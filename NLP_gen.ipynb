{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# how to access the main colab drive to save libirary permentaluy\n",
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "nb_path = '/content/notebooks'\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', nb_path)\n",
        "sys.path.insert(0,nb_path)"
      ],
      "metadata": {
        "id": "a9QyuQGa2Yw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --target=$nb_path git+https://github.com/boudinfl/pke.git\n",
        "!pip install --target=$nb_path wikipedia\n",
        "!pip install --target=$nb_path flashtext"
      ],
      "metadata": {
        "id": "mvCLyPLQ2a4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNcy5Ld_4L-k",
        "outputId": "1a5cbd3d-ead2-4063-b7a8-685063897398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pke\n",
        "import wikipedia\n",
        "from nltk.corpus import stopwords, words\n",
        "WK_AI = wikipedia.summary(\"Artificialintelligence\", sentences=10)\n",
        "print(WK_AI)"
      ],
      "metadata": {
        "id": "T5vhBzKk-y10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d2bb2bf-3b40-46c3-e064-13500b66fcdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to the natural intelligence displayed by animals and humans. AI research has been defined as the field of study of intelligent agents, which refers to any system that perceives its environment and takes actions that maximize its chance of achieving its goals.The term \"artificial intelligence\" had previously been used to describe machines that mimic and display \"human\" cognitive skills that are associated with the human mind, such as \"learning\" and \"problem-solving\". This definition has since been rejected by major AI researchers who now describe AI in terms of rationality and acting rationally, which does not limit how intelligence can be articulated.AI applications include advanced web search engines (e.g., Google), recommendation systems (used by YouTube, Amazon and Netflix), understanding human speech (such as Siri and Alexa), self-driving cars (e.g., Tesla), automated decision-making and competing at the highest level in strategic game systems (such as chess and Go).\n",
            "As machines become increasingly capable, tasks considered to require \"intelligence\" are often removed from the definition of AI, a phenomenon known as the AI effect. For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.Artificial intelligence was founded as an academic discipline in 1956, and in the years since has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an \"AI winter\"), followed by new approaches, success and renewed funding. AI research has tried and discarded many different approaches since its founding, including simulating the brain, modeling human problem solving, formal logic, large databases of knowledge and imitating animal behavior. In the first decades of the 21st century, highly mathematical-statistical machine learning has dominated the field, and this technique has proved highly successful, helping to solve many challenging problems throughout industry and academia.The various sub-fields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and the ability to move and manipulate objects. General intelligence (the ability to solve an arbitrary problem) is among the field's long-term goals. To solve these problems, AI researchers have adapted and integrated a wide range of problem-solving techniques â€“ including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, probability and economics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(f):\n",
        "    \n",
        "    lines = f\n",
        "    all_words = lines.split()  # split all words, but it not words only its contain number and other things\n",
        "\n",
        "    # step 1 : to make words contain alphabetic only\n",
        "    alphabetic_only = [word for word in all_words if word.isalpha()]  # get  alphabetic only\n",
        "\n",
        "    # step 2 : remove non-english word\n",
        "    # words_nltk = set(words.words())  ## english word\n",
        "    # english_alphabetic_only = [word for word in alphabetic_only if word in words_nltk]\n",
        "\n",
        "    # step 3 : convert all words into lowercase\n",
        "    lower_case_only = [word.lower() for word in alphabetic_only]\n",
        "\n",
        "    # step 4 : drop all the stop words\n",
        "    stopwords_nltk = set(stopwords.words('english'))  ## all stop words\n",
        "    clean_words = [word for word in lower_case_only if word not in stopwords_nltk]\n",
        "    return clean_words"
      ],
      "metadata": {
        "id": "QjRh-09E2OuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' '.join(clean_text(WK_AI))\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOlZj8Kp2lZv",
        "outputId": "1e535982-914b-4a16-ce39-dab329ab930d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "artificial intelligence intelligence demonstrated opposed natural intelligence displayed animals ai research defined field study intelligent refers system perceives environment takes actions maximize chance achieving term previously used describe machines mimic display cognitive skills associated human definition since rejected major ai researchers describe ai terms rationality acting limit intelligence applications include advanced web search engines recommendation systems amazon understanding human speech siri cars automated competing highest level strategic game systems chess machines become increasingly tasks considered require often removed definition phenomenon known ai optical character recognition frequently excluded things considered become routine intelligence founded academic discipline years since experienced several waves followed disappointment loss funding followed new success renewed ai research tried discarded many different approaches since including simulating modeling human problem formal large databases knowledge imitating animal first decades highly machine learning dominated technique proved highly helping solve many challenging problems throughout industry various ai research centered around particular goals use particular traditional goals ai research include knowledge natural language ability move manipulate general intelligence ability solve arbitrary among solve ai researchers adapted integrated wide range techniques including search mathematical formal artificial neural methods based probability\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pke_modeling(model,text1):\n",
        "  \n",
        "  # initialize keyphrase extraction model, here TopicRank\n",
        "  extractor = model\n",
        "\n",
        "  # load the content of the document, here document is expected to be a simple \n",
        "  # test string and preprocessing is carried out using spacy\n",
        "  extractor.load_document(input= text1 , language='en')\n",
        "\n",
        "  # keyphrase candidate selection, in the case of TopicRank: sequences of nouns\n",
        "  # and adjectives (i.e. `(Noun|Adj)*`)\n",
        "  extractor.candidate_selection()\n",
        "\n",
        "  # candidate weighting, in the case of TopicRank: using a random walk algorithm\n",
        "  extractor.candidate_weighting()\n",
        "\n",
        "  # N-best selection, keyphrases contains the 10 highest scored candidates as+-+6\n",
        "  # (keyphrase, score) tuples\n",
        "  keyphrases = extractor.get_n_best(n=10)\n",
        "  keys = list(zip(*keyphrases))[0]\n",
        "  print(keys)"
      ],
      "metadata": {
        "id": "ixG79gh3OEwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_models = [pke.unsupervised.TextRank(),pke.unsupervised.SingleRank()]\n",
        "pke_modeling(all_models[1],text)"
      ],
      "metadata": {
        "id": "sjc6Q0LwgSHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keyphrase sentance mapping \n",
        "from nltk.tokenize import sent_tokenize\n",
        "from flashtext import KeywordProcessor\n",
        "\n",
        "def tokenize_sentences(text):\n",
        "    sentences = [sent_tokenize(text)]\n",
        "    sentences = [y for x in sentences for y in x]\n",
        "    # Remove any short sentences less than 20 letters.\n",
        "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
        "    return sentences\n",
        "\n",
        "def get_sentences_for_keyword(keywords, sentences):\n",
        "    keyword_processor = KeywordProcessor()\n",
        "    keyword_sentences = {}\n",
        "    for word in keywords:\n",
        "        keyword_sentences[word] = []\n",
        "        keyword_processor.add_keyword(word)\n",
        "    for sentence in sentences:\n",
        "        keywords_found = keyword_processor.extract_keywords(sentence)\n",
        "        for key in keywords_found:\n",
        "            keyword_sentences[key].append(sentence)\n",
        "\n",
        "    for key in keyword_sentences.keys():\n",
        "        values = keyword_sentences[key]\n",
        "        values = sorted(values, key=len, reverse=True)\n",
        "        keyword_sentences[key] = values\n",
        "    return keyword_sentences\n",
        "\n",
        "# summarized_text is text after clean \n",
        "summarized_text = text\n",
        "sentences = tokenize_sentences(summarized_text)\n",
        "filtered_keys = keys\n",
        "keyword_sentence_mapping = get_sentences_for_keyword(filtered_keys, sentences)\n",
        "        \n",
        "print (keyword_sentence_mapping)"
      ],
      "metadata": {
        "id": "MmOfZ4YRG9aj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}